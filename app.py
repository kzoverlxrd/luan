#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ½å®‰ç…¤é«˜ç‚‰ç¢³æ’æ”¾ç›‘æ§ä¸ç®¡ç†ç³»ç»Ÿ - Streamlit Webåº”ç”¨
"""

import streamlit as st
import pandas as pd
import numpy as np
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import sys
import os
import matplotlib
import plotly
import plotly.graph_objects as go
import matplotlib.font_manager as fm
import matplotlib.pyplot as plt
import os

# å­—ä½“æ–‡ä»¶è·¯å¾„
font_path = os.path.join(os.path.dirname(__file__), "fonts", "NotoSansSC-Regular.otf")
if os.path.exists(font_path):
    my_font = fm.FontProperties(fname=font_path)
    # fm._rebuild()  # å¼ºåˆ¶é‡å»ºå­—ä½“ç¼“å­˜ï¼ˆæ–°ç‰ˆmatplotlibå·²æ— æ­¤æ–¹æ³•ï¼Œç›´æ¥æ³¨é‡Šæ‰ï¼‰
    plt.rcParams['font.sans-serif'] = [my_font.get_name()]
    plt.rcParams['axes.unicode_minus'] = False
else:
    my_font = None
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False 
from src.feature_name_map import en2zh
from create_dummy_data import calculate_carbon_emission_wsa

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from data_handler import DataHandler
from model_trainer import ModelTrainer

# å°è¯•å¯¼å…¥SHAP
try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False
    st.warning("SHAPåº“æœªå®‰è£…ï¼Œæ™ºèƒ½è¯Šæ–­åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚è¯·è¿è¡Œ: pip install shap")

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ½å®‰ç…¤é«˜ç‚‰ç¢³æ’æ”¾ç›‘æ§ä¸ç®¡ç†ç³»ç»Ÿ",
    page_icon="ğŸ­",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ’å…¥è‡ªå®šä¹‰CSSç¾åŒ–tabæ¨ªå‘åˆ†å¸ƒ
st.markdown("""
    <style>
    .stTabs [data-baseweb="tab-list"] {
        justify-content: center;
        gap: 22px;
    }
    .stTabs [data-baseweb="tab"] {Â·
        font-size: 1.15em;
        font-weight: 500;
        color: #222;
        padding: 0.5em 1.5em;
    }
    .stTabs [aria-selected="true"] {
        color: #e53935 !important;
        border-bottom: 3px solid #e53935 !important;
        background: none !important;
    }
    .stTabs [aria-selected="false"]:hover {
        color: #1976d2 !important;
        background: #f5f5f5 !important;
    }
    </style>
""", unsafe_allow_html=True)

# è®¾ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Noto Sans CJK SC', 'Arial Unicode MS', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

# æ›´æ–°æ˜ å°„
if 'coal_ratio' in en2zh:
    en2zh['coal_ratio'] = 'ç…¤æ¯”'
if 'coke_ratio' in en2zh:
    en2zh['coke_ratio'] = 'ç„¦æ¯”'
if 'coke_consumption_total' in en2zh:
    en2zh['coke_consumption_total'] = 'ç„¦ç‚­æ¶ˆè€—'

@st.cache_data
def load_data():
    """
    ç¼“å­˜åŠ è½½æ•°æ®
    """
    try:
        data_handler = DataHandler("data/daily_production_data.csv")
        X, y = data_handler.process()
        
        if X is not None and y is not None and data_handler.data is not None:
            # è·å–åŸå§‹æ•°æ®ç”¨äºæ˜¾ç¤º
            raw_data = data_handler.data.copy()
            raw_data['date'] = pd.to_datetime(raw_data['date'])
            raw_data.set_index('date', inplace=True)
            
            return X, y, raw_data, data_handler
        else:
            st.error("æ•°æ®åŠ è½½å¤±è´¥")
            return None, None, None, None
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½é”™è¯¯: {e}")
        return None, None, None, None

@st.cache_resource
def load_model():
    """
    ç¼“å­˜åŠ è½½æ¨¡å‹
    """
    try:
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        model_path = "models/xgboost_carbon_model.json"
        if not os.path.exists(model_path):
            st.warning("æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£åœ¨è®­ç»ƒæ–°æ¨¡å‹...")
            return train_new_model()
        
        # åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹
        model = xgb.XGBRegressor()
        model.load_model(model_path)
        
        # åŠ è½½æ¨¡å‹ä¿¡æ¯
        info_path = "models/model_info.json"
        if os.path.exists(info_path):
            import json
            with open(info_path, 'r', encoding='utf-8') as f:
                model_info = json.load(f)
            return model, model_info
        else:
            return model, None
            
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½é”™è¯¯: {e}")
        return None, None

def train_new_model():
    """
    è®­ç»ƒæ–°æ¨¡å‹
    """
    try:
        X, y, _, _ = load_data()
        if X is not None and y is not None:
            trainer = ModelTrainer(test_size=0.2, random_state=42)
            model = trainer.train(X, y)
            
            # è·å–æ¨¡å‹ä¿¡æ¯
            model_info = {
                'feature_names': trainer.feature_names,
                'test_size': trainer.test_size,
                'random_state': trainer.random_state
            }
            
            return model, model_info
        else:
            return None, None
    except Exception as e:
        st.error(f"æ¨¡å‹è®­ç»ƒé”™è¯¯: {e}")
        return None, None

def get_prediction_for_date(model, X, raw_data, selected_date):
    """
    è·å–æŒ‡å®šæ—¥æœŸçš„é¢„æµ‹å€¼å’ŒWSAå…¬å¼å®é™…å€¼
    """
    try:
        if selected_date in X.index:
            features = X.loc[selected_date:selected_date]
            prediction = model.predict(features)[0]
            # ç”¨WSAå…¬å¼åŠ¨æ€è®¡ç®—å®é™…è®°å½•å€¼
            actual = calculate_carbon_emission_wsa(features.iloc[0])
            return prediction, actual
        else:
            return None, None
    except Exception as e:
        st.error(f"é¢„æµ‹é”™è¯¯: {e}")
        return None, None

def create_emission_chart(raw_data, selected_date):
    """
    åˆ›å»ºç¢³æ’æ”¾è¶‹åŠ¿å›¾
    """
    try:
        # è·å–æœ€è¿‘30å¤©çš„æ•°æ®
        end_date = selected_date
        start_date = end_date - timedelta(days=30)
        
        # è¿‡æ»¤æ•°æ®
        chart_data = raw_data[(raw_data.index >= start_date) & (raw_data.index <= end_date)]
        
        if len(chart_data) > 0:
            fig, ax = plt.subplots(figsize=(12, 6))
            
            # ç»˜åˆ¶ç¢³æ’æ”¾è¶‹åŠ¿
            ax.plot(chart_data.index, chart_data['carbon_emission_co2'], 
                   marker='o', linewidth=2, markersize=6, label='å®é™…ç¢³æ’æ”¾')
            
            # é«˜äº®æ˜¾ç¤ºé€‰ä¸­æ—¥æœŸ
            if selected_date in chart_data.index:
                ax.scatter(selected_date, chart_data.loc[selected_date, 'carbon_emission_co2'], 
                          color='red', s=100, zorder=5, label='é€‰ä¸­æ—¥æœŸ')
            
            ax.set_xlabel('æ—¥æœŸ', fontproperties=my_font)
            ax.set_ylabel('ç¢³æ’æ”¾é‡ (å¨CO2)', fontproperties=my_font)
            ax.set_title('æœ€è¿‘30å¤©ç¢³æ’æ”¾è¶‹åŠ¿', fontproperties=my_font)
            ax.legend(prop=my_font)
            ax.grid(True, alpha=0.3)
            
            # æ—‹è½¬xè½´æ ‡ç­¾
            plt.xticks(rotation=45)
            plt.tight_layout()
            
            return fig
        else:
            return None
    except Exception as e:
        st.error(f"å›¾è¡¨åˆ›å»ºé”™è¯¯: {e}")
        return None

def create_shap_waterfall(model, X, selected_date, feature_names):
    """
    åˆ›å»ºSHAPç€‘å¸ƒå›¾ï¼Œç‰¹å¾åã€æ ‡ç­¾ã€æ ‡é¢˜å…¨éƒ¨ä¸­æ–‡
    """
    try:
        import shap
        sample_data = X.loc[selected_date:selected_date]
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(sample_data)
        # ä¸­æ–‡ç‰¹å¾å
        feature_names_zh = [en2zh.get(f, f) for f in feature_names]
        fig, ax = plt.subplots(figsize=(12, 8))
        shap.waterfall_plot(
            shap.Explanation(
                values=shap_values[0],
                base_values=explainer.expected_value,
                data=sample_data.iloc[0].values,
                feature_names=feature_names_zh
            ),
            show=False
        )
        plt.title(f'SHAPç€‘å¸ƒå›¾ - {selected_date.strftime("%Y-%m-%d")} ç¢³æ’æ”¾é¢„æµ‹è§£é‡Š', fontsize=14, fontweight='bold', fontproperties=my_font)
        plt.xlabel('SHAPå€¼ï¼ˆå¯¹é¢„æµ‹çš„å½±å“ï¼‰', fontsize=12, fontproperties=my_font)
        plt.tight_layout()
        return fig, None
    except Exception as e:
        return None, f"SHAPåˆ†æé”™è¯¯: {e}"

def get_shap_interpretation(shap_values, feature_names, sample_data):
    """
    è·å–SHAPè§£é‡Šæ–‡æœ¬
    """
    try:
        if not SHAP_AVAILABLE:
            return "SHAPåº“æœªå®‰è£…ï¼Œæ— æ³•æä¾›è¯¦ç»†è§£é‡Šã€‚"
        
        # è·å–æœ€é‡è¦çš„ç‰¹å¾ï¼ˆæŒ‰SHAPå€¼ç»å¯¹å€¼æ’åºï¼‰
        feature_importance = list(zip(feature_names, abs(shap_values[0])))
        feature_importance.sort(key=lambda x: x[1], reverse=True)
        
        # è·å–å‰5ä¸ªæœ€é‡è¦çš„ç‰¹å¾
        top_features = feature_importance[:5]
        
        interpretation = "## ğŸ” æ™ºèƒ½è¯Šæ–­åˆ†æç»“æœ\n\n"
        interpretation += "### ä¸»è¦å½±å“å› ç´ åˆ†æï¼š\n\n"
        
        for i, (feature, importance) in enumerate(top_features, 1):
            feature_zh = en2zh.get(feature, feature)
            feature_value = sample_data.iloc[0][feature]
            shap_value = shap_values[0][feature_names.index(feature)]
            
            # æ ¹æ®SHAPå€¼åˆ¤æ–­å½±å“æ–¹å‘
            if shap_value > 0:
                direction = "å¢åŠ "
                impact = "æ¨é«˜"
            else:
                direction = "å‡å°‘"
                impact = "é™ä½"
            
            interpretation += f"**{i}. {feature_zh}**\n"
            interpretation += f"- å½“å‰å€¼: {feature_value:.4f}\n"
            interpretation += f"- å½±å“ç¨‹åº¦: {abs(shap_value):.2f}\n"
            interpretation += f"- å½±å“æ–¹å‘: {direction}ç¢³æ’æ”¾ ({impact}é¢„æµ‹å€¼)\n\n"
        
        # æ€»ä½“è§£é‡Š
        total_impact = sum(shap_values[0])
        if total_impact > 0:
            overall_effect = "é«˜äºå¹³å‡æ°´å¹³"
        else:
            overall_effect = "ä½äºå¹³å‡æ°´å¹³"
        
        interpretation += f"### æ€»ä½“åˆ†æï¼š\n"
        interpretation += f"å½“å‰ç”Ÿäº§æ¡ä»¶ä¸‹çš„ç¢³æ’æ”¾é¢„æµ‹å€¼{overall_effect}ã€‚\n"
        interpretation += f"ä¸»è¦å½±å“å› ç´ åŒ…æ‹¬ä¸Šè¿°ç‰¹å¾ï¼Œå…¶ä¸­{top_features[0][0]}çš„å½±å“æœ€ä¸ºæ˜¾è‘—ã€‚\n\n"
        
        interpretation += "### ä¼˜åŒ–å»ºè®®ï¼š\n"
        for feature, importance in top_features[:3]:
            feature_zh = en2zh.get(feature, feature)
            shap_value = shap_values[0][feature_names.index(feature)]
            if shap_value > 0:
                interpretation += f"- è€ƒè™‘ä¼˜åŒ– **{feature_zh}** ä»¥é™ä½ç¢³æ’æ”¾\n"
            else:
                interpretation += f"- ä¿æŒ **{feature_zh}** åœ¨å½“å‰æ°´å¹³\n"
        
        return interpretation
        
    except Exception as e:
        return f"è§£é‡Šç”Ÿæˆé”™è¯¯: {e}"

def create_simulation_data(X, selected_date, coal_ratio, luan_coal_ash_avg, blast_temp_avg):
    """
    åˆ›å»ºä»¿çœŸæ•°æ®
    """
    try:
        if X is None or selected_date not in X.index:
            return None, None
        
        # è·å–åŸå§‹æ•°æ®
        original_data = X.loc[selected_date:selected_date].copy()
        
        # åˆ›å»ºä»¿çœŸæ•°æ®
        simulation_data = original_data.copy()
        
        # æ›´æ–°å…³é”®å‚æ•°
        simulation_data['coal_ratio'] = coal_ratio
        simulation_data['luan_coal_ash_avg'] = luan_coal_ash_avg
        simulation_data['blast_temp_avg'] = blast_temp_avg
        
        # æ›´æ–°ç›¸å…³çš„äº¤å‰ç‰¹å¾
        simulation_data['volatility_effect'] = coal_ratio * simulation_data['luan_coal_vd_avg'].iloc[0]
        simulation_data['ash_burden_effect'] = coal_ratio * luan_coal_ash_avg
        simulation_data['effective_carbon_input'] = coal_ratio * simulation_data['luan_coal_fcad_avg'].iloc[0]
        
        return simulation_data, original_data
        
    except Exception as e:
        st.error(f"ä»¿çœŸæ•°æ®åˆ›å»ºé”™è¯¯: {e}")
        return None, None

def get_parameter_ranges(X):
    """
    è·å–å‚æ•°èŒƒå›´
    """
    if X is None:
        return {
            'coal_ratio': {'min': 0.0, 'max': 1.0, 'current': 0.5},
            'luan_coal_ash_avg': {'min': 0.0, 'max': 50.0, 'current': 25.0},
            'blast_temp_avg': {'min': 800.0, 'max': 1200.0, 'current': 1000.0}
        }
    
    ranges = {
        'coal_ratio': {
            'min': float(X['coal_ratio'].min()),
            'max': float(X['coal_ratio'].max()),
            'current': float(X['coal_ratio'].mean())
        },
        'luan_coal_ash_avg': {
            'min': float(X['luan_coal_ash_avg'].min()),
            'max': float(X['luan_coal_ash_avg'].max()),
            'current': float(X['luan_coal_ash_avg'].mean())
        },
        'blast_temp_avg': {
            'min': float(X['blast_temp_avg'].min()),
            'max': float(X['blast_temp_avg'].max()),
            'current': float(X['blast_temp_avg'].mean())
        }
    }
    return ranges

def create_sensitivity_analysis(model, X, selected_date, param_name, param_range, steps=20):
    """
    åˆ›å»ºå‚æ•°æ•æ„Ÿæ€§åˆ†æ
    """
    try:
        if X is None or selected_date not in X.index:
            return None, None
        # è·å–åŸå§‹æ•°æ®
        original_data = X.loc[selected_date:selected_date].copy()
        # åˆ›å»ºå‚æ•°å˜åŒ–åºåˆ—
        param_values = np.linspace(param_range['min'], param_range['max'], steps)
        predictions = []
        for value in param_values:
            # åˆ›å»ºä»¿çœŸæ•°æ®
            simulation_data = original_data.copy()
            if param_name == 'coal_ratio':
                simulation_data[param_name] = value / 1000  # è¿˜åŸä¸ºåŸå§‹æ¯”å€¼
                # æ›´æ–°ç›¸å…³çš„äº¤å‰ç‰¹å¾
                simulation_data['volatility_effect'] = (value / 1000) * simulation_data['luan_coal_vd_avg'].iloc[0]
                simulation_data['ash_burden_effect'] = (value / 1000) * simulation_data['luan_coal_ash_avg'].iloc[0]
                simulation_data['effective_carbon_input'] = (value / 1000) * simulation_data['luan_coal_fcad_avg'].iloc[0]
            elif param_name == 'luan_coal_ash_avg':
                simulation_data[param_name] = value
                simulation_data['ash_burden_effect'] = simulation_data['coal_ratio'].iloc[0] * value
            else:
                simulation_data[param_name] = value
            # é¢„æµ‹
            prediction = model.predict(simulation_data)[0]
            predictions.append(prediction)
        return param_values, predictions
    except Exception as e:
        st.error(f"æ•æ„Ÿæ€§åˆ†æé”™è¯¯: {e}")
        return None, None

def plot_sensitivity_analysis(param_values, predictions, param_name, original_value):
    """
    ç»˜åˆ¶æ•æ„Ÿæ€§åˆ†æå›¾
    """
    try:
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # ç»˜åˆ¶æ•æ„Ÿæ€§æ›²çº¿
        ax.plot(param_values, predictions, 'b-', linewidth=2, label='é¢„æµ‹ç¢³æ’æ”¾')
        
        # æ ‡è®°åŸå§‹å€¼
        import numpy as np
        param_values_arr = np.array(param_values)
        original_prediction = predictions[np.argmin(np.abs(param_values_arr - original_value))]
        ax.axvline(x=original_value, color='r', linestyle='--', alpha=0.7, label='åŸå§‹å€¼')
        ax.axhline(y=original_prediction, color='g', linestyle='--', alpha=0.7, label='åŸå§‹é¢„æµ‹')
        
        # è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
        param_labels = {
            'coal_ratio': 'ç…¤æ¯”ç‡',
            'luan_coal_ash_avg': 'æ½å®‰ç…¤ç°åˆ† (%)',
            'blast_temp_avg': 'é¼“é£æ¸©åº¦ (Â°C)'
        }
        
        xlabel = param_labels.get(param_name, str(param_name))
        ax.set_xlabel(xlabel, fontproperties=my_font)
        ax.set_ylabel('é¢„æµ‹ç¢³æ’æ”¾é‡ (å¨CO2)', fontproperties=my_font)
        ax.set_title(f'{param_labels.get(param_name, param_name)}æ•æ„Ÿæ€§åˆ†æ', fontproperties=my_font)
        ax.legend(prop=my_font)
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        return fig
        
    except Exception as e:
        st.error(f"å›¾è¡¨åˆ›å»ºé”™è¯¯: {e}")
        return None

def main():
    """
    ä¸»å‡½æ•°
    """
    # æ ‡é¢˜
    st.title("é«˜ç‚‰ç¢³æ’æ”¾ç›‘æ§ä¸é¢„æµ‹ç³»ç»Ÿ")
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ç¢³æ’æ”¾ç›‘æ§",
        "æ™ºèƒ½è¯Šæ–­åˆ†æ",
        "ä»¿çœŸä¸ä¼˜åŒ–",
        "æ½å®‰ç…¤ç‰¹æ€§å½±å“æƒé‡åˆ†æ",
        "èƒ½åŠ›åˆ†æåŠæŠ€æœ¯æ€»ç»“"
    ])

    with tab1:
        # ä¾§è¾¹æ ï¼šæ·»åŠ å¯¼å…¥æ•°æ®åŠŸèƒ½
        st.sidebar.header("ğŸ“‚ æ•°æ®å¯¼å…¥ä¸ç®¡ç†")
        uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ ç”Ÿäº§æ•°æ®CSVæ–‡ä»¶ï¼ˆå­—æ®µéœ€ä¸æ¨¡æ¿ä¸€è‡´ï¼‰", type=["csv"], help="è¯·ä¸Šä¼ åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µçš„CSVæ–‡ä»¶")
        if uploaded_file is not None:
            try:
                # è‡ªåŠ¨å°è¯•utf-8å’Œgbkç¼–ç 
                try:
                    df = pd.read_csv(uploaded_file, encoding='utf-8')
                except UnicodeDecodeError:
                    uploaded_file.seek(0)
                    df = pd.read_csv(uploaded_file, encoding='gbk')
                # å­—æ®µæ ¡éªŒ
                required_cols = [
                    'date', 'blast_temp_avg', 'blast_volume_total', 'coke_consumption_total',
                    'luan_coal_injection_total', 'luan_coal_ash_avg', 'luan_coal_vd_avg',
                    'luan_coal_fcad_avg', 'iron_output_total', 'carbon_emission_co2'
                ]
                missing = [col for col in required_cols if col not in df.columns]
                if missing:
                    st.sidebar.error(f"ç¼ºå°‘å­—æ®µ: {', '.join(missing)}ï¼Œè¯·æ£€æŸ¥æ¨¡æ¿ï¼")
                else:
                    # ä¿å­˜åˆ°dataç›®å½•
                    save_path = os.path.join("data", "daily_production_data.csv")
                    df.to_csv(save_path, index=False)

                    # è‡ªåŠ¨æ¸…æ´—å’Œè¡¥å…¨carbon_emission_co2ï¼ˆä½¿ç”¨å…¨å±€importçš„WSAå…¬å¼ï¼‰
                    df = df.dropna(how='all', subset=df.columns[1:])
                    # è¦†ç›–æ‰€æœ‰ç¢³æ’æ”¾é‡ä¸ºWSAå…¬å¼è®¡ç®—å€¼
                    df['carbon_emission_co2'] = df.apply(calculate_carbon_emission_wsa, axis=1)
                    df = df.dropna(subset=['carbon_emission_co2'])
                    df.to_csv(save_path, index=False)
                    st.sidebar.success("âœ… æ•°æ®ä¸Šä¼ ã€æ¸…æ´—å¹¶è¡¥å…¨æˆåŠŸï¼")
                    st.sidebar.info("âš ï¸ å¦‚éœ€åŠ è½½æ–°æ•°æ®ï¼Œè¯·ç‚¹å‡»é¡µé¢å³ä¸Šè§’èœå•ï¼Œé€‰æ‹©'Clear cache'ååˆ·æ–°é¡µé¢ã€‚")
                    # é€‰æ‹©æ˜¯å¦é‡æ–°è®­ç»ƒæ¨¡å‹
                    retrain = st.sidebar.checkbox("ä¸Šä¼ åç«‹å³é‡æ–°è®­ç»ƒæ¨¡å‹", value=True)
                    if retrain:
                        with st.spinner("æ­£åœ¨é‡æ–°è®­ç»ƒæ¨¡å‹..."):
                            model, model_info = train_new_model()
                        st.sidebar.success("æ¨¡å‹è®­ç»ƒå®Œæˆï¼è¯·åˆ·æ–°é¡µé¢ä½“éªŒæ–°æ•°æ®ã€‚")
                    else:
                        st.sidebar.info("æ•°æ®å·²ä¿å­˜ï¼Œå¦‚éœ€ç”Ÿæ•ˆè¯·æ‰‹åŠ¨é‡æ–°è®­ç»ƒæ¨¡å‹æˆ–åˆ·æ–°é¡µé¢ã€‚")
            except Exception as e:
                st.sidebar.error(f"æ•°æ®å¯¼å…¥å¤±è´¥: {e}\nè¯·ç¡®è®¤æ–‡ä»¶ç¼–ç ä¸ºUTF-8æˆ–GBKï¼Œå¹¶æ£€æŸ¥å­—æ®µæ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
        
        # ä¾§è¾¹æ ï¼šæ·»åŠ å¼ºåˆ¶åˆ·æ–°æŒ‰é’®
        if st.sidebar.button("ğŸ”„ æ•°æ®åˆ·æ–°"):
            st.rerun()
    
        # åŠ è½½æ•°æ®å’Œæ¨¡å‹
        with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®å’Œæ¨¡å‹..."):
            X, y, raw_data, data_handler = load_data()
            model, model_info = load_model()
        
        if X is None or model is None:
            st.error("ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®å’Œæ¨¡å‹æ–‡ä»¶")
            return
        
        # ä¾§è¾¹æ 
        st.sidebar.header("ğŸ“… æ—¥æœŸé€‰æ‹©")
        
        # è·å–å¯ç”¨æ—¥æœŸèŒƒå›´
        if raw_data is not None:
            available_dates = raw_data.index.tolist()
            min_date = min(available_dates)
            max_date = max(available_dates)
        else:
            st.error("æ•°æ®åŠ è½½å¤±è´¥")
            return
        
        # æ—¥æœŸé€‰æ‹©å™¨
        selected_date = st.sidebar.date_input(
            "é€‰æ‹©æ—¥æœŸ",
            value=max_date.date(),
            min_value=min_date.date(),
            max_value=max_date.date()
        )
        
        # è½¬æ¢ä¸ºdatetime
        selected_date = pd.Timestamp(selected_date)
        
        # ä¾§è¾¹æ æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
        st.sidebar.markdown("---")
        st.sidebar.header("ğŸ“Š ç³»ç»Ÿä¿¡æ¯")
        if raw_data is not None:
            st.sidebar.metric("æ•°æ®æ€»å¤©æ•°", len(raw_data))
        if X is not None:
            st.sidebar.metric("ç‰¹å¾æ•°é‡", len(X.columns))
        st.sidebar.metric("æ¨¡å‹ç±»å‹", "XGBoost")
        
        # ä¸»é¢æ¿
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.header("ğŸ“ˆ ç¢³æ’æ”¾ç›‘æ§")

            # è·å–é¢„æµ‹å€¼å’Œå®é™…å€¼ï¼ˆæå‰ï¼‰
            prediction, actual = get_prediction_for_date(model, X, raw_data, selected_date)

            # 1. å¥åº·åº¦ä»ªè¡¨ç›˜ï¼ˆç¾åŒ–ç‰ˆï¼‰
            import plotly.graph_objects as go
            gauge_min = 8000
            gauge_green = 9100
            gauge_yellow = 9300
            gauge_max = 10000
            if prediction is not None:
                fig = go.Figure(go.Indicator(
                    mode="gauge+number",
                    value=prediction,
                    number={'font': {'size': 32, 'color': '#222'}, 'suffix': " å¨COâ‚‚"},
                    title={'text': "<b>ç¢³æ’æ”¾ç»©æ•ˆ</b>", 'font': {'size': 20}},
                    gauge={
                        'axis': {'range': [gauge_min, gauge_max], 'tickwidth': 1, 'tickcolor': "#888"},
                        'bar': {'color': "#2b7cff", 'thickness': 0.25},
                        'bgcolor': "white",
                        'borderwidth': 2,
                        'bordercolor': "#eee",
                        'steps': [
                            {'range': [gauge_min, gauge_green], 'color': "#b6e3b6"},
                            {'range': [gauge_green, gauge_yellow], 'color': "#ffe699"},
                            {'range': [gauge_yellow, gauge_max], 'color': "#ffb3b3"}
                        ],
                        'threshold': {
                            'line': {'color': "#222", 'width': 4},
                            'thickness': 0.8,
                            'value': prediction
                        }
                    }
                ))
                fig.update_layout(
                    margin=dict(l=10, r=10, t=40, b=10),
                    width=500,
                    height=350,
                    paper_bgcolor="white"
                )
                st.plotly_chart(fig, use_container_width=False)

            # 2. æŒ‡æ ‡å¡ç‰‡å’Œå½“æ—¥ç”Ÿäº§æ•°æ®è¡¨æ ¼ï¼ˆç´§å‡‘æ’ç‰ˆï¼‰
            prediction, actual = get_prediction_for_date(model, X, raw_data, selected_date)
            if prediction is not None and actual is not None:
                col1_1, col1_2, col1_3 = st.columns(3)
                with col1_1:
                    st.metric(
                        label="æ¨¡å‹é¢„æµ‹å€¼ï¼ˆå¨CO2ï¼‰",
                        value=f"{prediction:.2f}",
                        delta=f"{prediction - actual:.2f}"
                    )
                with col1_2:
                    st.metric(
                        label="å®é™…è®°å½•å€¼ï¼ˆå¨CO2ï¼‰",
                        value=f"{actual:.2f}",
                        delta=None
                    )
                with col1_3:
                    error_rate = abs(prediction - actual) / actual * 100
                    st.metric(
                        label="é¢„æµ‹è¯¯å·®ç‡",
                        value=f"{error_rate:.2f}%",
                        delta=None
                    )
                # å½“æ—¥ç”Ÿäº§æ•°æ®è¡¨æ ¼ï¼ˆç´§è·Ÿåœ¨æŒ‡æ ‡å¡ç‰‡ä¸‹æ–¹ï¼‰
                st.subheader("ğŸ“‹ å½“æ—¥ç”Ÿäº§æ•°æ®")
                if raw_data is not None and selected_date in raw_data.index:
                    daily_data = raw_data.loc[selected_date]
                    detail_items = [
                        ("é¼“é£æ¸©åº¦ (Â°C)", f"{daily_data['blast_temp_avg']:.2f}"),
                        ("é¼“é£é‡ (mÂ³)", f"{daily_data['blast_volume_total']:.2f}"),
                        ("ç„¦ç‚­æ¶ˆè€— (å¨)", f"{daily_data['coke_consumption_total']:.2f}"),
                        ("æ½å®‰ç…¤å–·å¹é‡ (å¨)", f"{daily_data['luan_coal_injection_total']:.2f}"),
                        ("æ½å®‰ç…¤ç°åˆ† (%)", f"{daily_data['luan_coal_ash_avg']:.2f}"),
                        ("æ½å®‰ç…¤æŒ¥å‘åˆ† (%)", f"{daily_data['luan_coal_vd_avg']:.2f}"),
                        ("æ½å®‰ç…¤å›ºå®šç¢³ (%)", f"{daily_data['luan_coal_fcad_avg']:.2f}"),
                        ("é“æ°´äº§é‡ (å¨)", f"{daily_data['iron_output_total']:.2f}")
                    ]
                    import numpy as np
                    if actual is not None and not (isinstance(actual, float) and np.isnan(actual)):
                        detail_items.append(("**ç¢³æ’æ”¾é‡ (å¨CO2)**", f"{actual:.2f}"))
                    detail_data = {
                        "æŒ‡æ ‡": [item[0] for item in detail_items],
                        "æ•°å€¼": [item[1] for item in detail_items]
                    }
                    detail_df = pd.DataFrame(detail_data)
                    st.dataframe(detail_df, use_container_width=True)

    with col2:
        st.header("ğŸ“Š è¶‹åŠ¿åˆ†æ")
        
        # åˆ›å»ºè¶‹åŠ¿å›¾
        fig = create_emission_chart(raw_data, selected_date)
        if fig is not None:
            st.pyplot(fig)
        
        # 3. è¶‹åŠ¿åˆ†æä¸€å¥è¯
        try:
            # å–æœ€è¿‘7å¤©ç¢³æ’æ”¾é‡
            recent_dates = [selected_date - timedelta(days=i) for i in range(6, -1, -1)]
            recent_data = [raw_data.loc[d, 'carbon_emission_co2'] for d in recent_dates if d in raw_data.index]
            import numpy as np
            if len(recent_data) >= 2:
                trend = np.polyfit(range(len(recent_data)), recent_data, 1)[0]
                if trend < 0:
                    trend_text = "è¿‡å»7å¤©ï¼Œç¢³æ’æ”¾å‘ˆä¸‹é™è¶‹åŠ¿ã€‚"
                else:
                    trend_text = "è¿‡å»7å¤©ï¼Œç¢³æ’æ”¾å‘ˆä¸Šå‡è¶‹åŠ¿ã€‚"
                volatility = np.std(recent_data)
                if volatility > 100:
                    trend_text += "ä½†æ³¢åŠ¨è¾ƒå¤§ã€‚"
                else:
                    trend_text += "æ³¢åŠ¨è¾ƒå°ã€‚"
                st.caption(trend_text)
        except Exception:
            pass
        
        # æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§
        if model_info and 'feature_names' in model_info:
            st.subheader("ğŸ¯ ç‰¹å¾é‡è¦æ€§")
            
            # è·å–ç‰¹å¾é‡è¦æ€§
            feature_importance = pd.DataFrame({
                'feature': model_info['feature_names'],
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            # æ˜¾ç¤ºå‰5ä¸ªé‡è¦ç‰¹å¾
            top_features = feature_importance.head(5)
            for idx, row in top_features.iterrows():
                st.metric(
                        label=en2zh.get(row['feature'], row['feature']),
                    value=f"{row['importance']:.4f}"
                )
    
    with tab2:
        # æ™ºèƒ½è¯Šæ–­åˆ†ææ¨¡å—
        st.markdown("---")
        st.header("ğŸ” æ™ºèƒ½è¯Šæ–­åˆ†æ")
        
        # æ£€æŸ¥SHAPæ˜¯å¦å¯ç”¨
        if not SHAP_AVAILABLE:
            st.warning("âš ï¸ SHAPåº“æœªå®‰è£…ï¼Œæ™ºèƒ½è¯Šæ–­åŠŸèƒ½ä¸å¯ç”¨ã€‚è¯·è¿è¡Œ: `pip install shap`")
        else:
            # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
            diag_col1, diag_col2 = st.columns([1, 1])
            
            with diag_col1:
                st.subheader("ğŸ“Š SHAPç€‘å¸ƒå›¾åˆ†æ")
                # æ™ºèƒ½è¯Šæ–­æŒ‰é’®
                if not st.button("ğŸš€ å¼€å§‹æ™ºèƒ½è¯Šæ–­", type="primary", key="diagnose_btn_left"):
                    with st.spinner("æ­£åœ¨è¿›è¡Œæ™ºèƒ½è¯Šæ–­åˆ†æ..."):
                        # åˆ›å»ºSHAPç€‘å¸ƒå›¾
                        waterfall_fig, error_msg = create_shap_waterfall(
                            model, X, selected_date, X.columns.tolist()
                        )
                        if waterfall_fig is not None:
                            st.pyplot(waterfall_fig)
                            # è·å–SHAPè§£é‡Šï¼ˆå¢å¼ºç‰ˆï¼Œå‰5ä¸ªç‰¹å¾ï¼Œå«å†å²å‡å€¼å¯¹æ¯”ï¼‰
                            if selected_date in X.index:
                                sample_data = X.loc[selected_date:selected_date]
                                explainer = shap.TreeExplainer(model)
                                shap_values = explainer.shap_values(sample_data)
                                feature_names = X.columns.tolist()
                                # å–å‰5ä¸ªé‡è¦ç‰¹å¾
                                top_indices = np.argsort(np.abs(shap_values[0]))[::-1][:5]
                                diagnosis = []
                                for idx in top_indices:
                                    feature = feature_names[idx]
                                    current_value = sample_data.iloc[0][feature]
                                    shap_value = shap_values[0][idx]
                                    mean_value = X[feature].mean()
                                    # å¯¹æ¯”æ–‡æœ¬
                                    if current_value > mean_value:
                                        compare_text = f"é«˜äºå†å²å‡å€¼ {mean_value:.2f}"
                                    elif current_value < mean_value:
                                        compare_text = f"ä½äºå†å²å‡å€¼ {mean_value:.2f}"
                                    else:
                                        compare_text = "ç­‰äºå†å²å‡å€¼"
                                    # å½±å“æ–¹å‘
                                    if shap_value > 0:
                                        direction = "æ¨é«˜ç¢³æ’æ”¾"
                                    else:
                                        direction = "é™ä½ç¢³æ’æ”¾"
                                    diagnosis.append(
                                        f"**{en2zh.get(feature, feature)}**ï¼šå½“å‰å€¼ {current_value:.2f}ï¼Œ{compare_text}ï¼Œ"
                                        f"å½±å“ç¨‹åº¦ {abs(shap_value):.2f}ï¼Œæ–¹å‘ï¼š{direction}"
                                    )
                                st.markdown("### ä¸»è¦å½±å“å› ç´ è¯¦ç»†è§£æï¼š")
                                for item in diagnosis:
                                    st.markdown(item)
                        else:
                            st.error(f"è¯Šæ–­åˆ†æå¤±è´¥: {error_msg}")
            
            with diag_col2:
                if st.button("ğŸš€ å¼€å§‹æ™ºèƒ½è¯Šæ–­", type="primary", key="diagnose_btn_right"):
                    st.subheader("ğŸ“ è¯Šæ–­è¯´æ˜")
                    st.markdown("""
                    **æ™ºèƒ½è¯Šæ–­åŠŸèƒ½è¯´æ˜ï¼š**
                    
                    ğŸ” **SHAPç€‘å¸ƒå›¾**ï¼šæ˜¾ç¤ºæ¯ä¸ªç‰¹å¾å¯¹é¢„æµ‹ç»“æœçš„å…·ä½“è´¡çŒ®
                    
                    ğŸ“Š **ç‰¹å¾å½±å“åˆ†æ**ï¼š
                    - æ­£å€¼ï¼šè¯¥ç‰¹å¾æ¨é«˜äº†ç¢³æ’æ”¾é¢„æµ‹
                    - è´Ÿå€¼ï¼šè¯¥ç‰¹å¾é™ä½äº†ç¢³æ’æ”¾é¢„æµ‹
                    
                    ğŸ’¡ **ä¼˜åŒ–å»ºè®®**ï¼šåŸºäºåˆ†æç»“æœæä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®
                    
                    âš¡ **ç‚¹å‡»"å¼€å§‹æ™ºèƒ½è¯Šæ–­"æŒ‰é’®å¼€å§‹åˆ†æ**
                    """)
                    # æ–°å¢ï¼šå³ä¾§æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
                    if selected_date in X.index:
                        sample_data = X.loc[selected_date:selected_date]
                        explainer = shap.TreeExplainer(model)
                        shap_values = explainer.shap_values(sample_data)
                        feature_names = X.columns.tolist()
                        top_indices = np.argsort(np.abs(shap_values[0]))[::-1][:5]
                        st.markdown("### ä¼˜åŒ–å»ºè®®ï¼š")
                        for idx in top_indices:
                            feature = feature_names[idx]
                            shap_value = shap_values[0][idx]
                            feature_zh = en2zh.get(feature, feature)
                            # é’ˆå¯¹ç‰¹å®šç‰¹å¾
                            if feature == "luan_coal_injection_total":
                                if shap_value < 0:
                                    st.info(f"å¢åŠ {feature_zh}æœ‰åŠ©äºé™ä½ç¢³æ’æ”¾")
                                # å¦‚æœshap_valueä¸ºæ­£ï¼Œä¸æ˜¾ç¤ºä»»ä½•ä¸æ½å®‰ç…¤å–·å¹é‡ç›¸å…³çš„å»ºè®®
                            elif feature == "coke_consumption_total":
                                if shap_value > 0:
                                    st.warning(f"{feature_zh}å¢åŠ ä¼šæ¨é«˜ç¢³æ’æ”¾ï¼Œå»ºè®®ä¼˜åŒ–")
                                else:
                                    st.info(f"é™ä½{feature_zh}æœ‰åŠ©äºå‡å°‘ç¢³æ’æ”¾")
                            else:
                                if shap_value > 0:
                                    st.info(f"å»ºè®®é€‚å½“é™ä½{feature_zh}ä»¥å‡å°‘ç¢³æ’æ”¾")
                                else:
                                    st.info(f"å½“å‰{feature_zh}æœ‰åŠ©äºé™ä½ç¢³æ’æ”¾ï¼Œå¯ä¿æŒ")

    with tab3:
        # ä»¿çœŸä¸ä¼˜åŒ–æ¨¡å—
        st.markdown("---")
        st.header("ğŸ›ï¸ ä»¿çœŸä¸ä¼˜åŒ–")
        
        # è·å–å‚æ•°èŒƒå›´
        param_ranges = get_parameter_ranges(X)
        
        # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
        sim_col1, sim_col2, sim_col3 = st.columns(3)
        
        with sim_col1:
            st.subheader("ğŸ“Š å‚æ•°è°ƒæ•´")
            # ç…¤æ¯”ï¼ˆkg/å¨é“æ°´ï¼‰æ»‘å—ï¼ŒèŒƒå›´110-210
            coal_ratio_min = 110
            coal_ratio_max = 210
            coal_ratio_current = int(param_ranges['coal_ratio']['current'] * 1000)
            coal_ratio_kg = st.slider(
                "ç…¤æ¯”ï¼ˆkg/å¨é“æ°´ï¼‰",
                min_value=coal_ratio_min,
                max_value=coal_ratio_max,
                value=int(X.loc[selected_date, 'coal_ratio'] * 1000) if selected_date in X.index else coal_ratio_current,
                step=1,
                help="è°ƒæ•´ç…¤å–·å¹é‡ä¸é“æ°´äº§é‡çš„æ¯”å€¼ï¼Œå•ä½ï¼škg/å¨é“æ°´"
            )
            coal_ratio = coal_ratio_kg / 1000  # è¿˜åŸä¸ºåŸå§‹æ¯”å€¼
            # ç„¦æ¯”ï¼ˆkg/å¨é“æ°´ï¼‰æ»‘å—ï¼ŒèŒƒå›´300-400
            coke_ratio_min = 300
            coke_ratio_max = 400
            coke_ratio_current = int(X.loc[selected_date, 'coke_ratio'] * 1000) if 'coke_ratio' in X.columns and selected_date in X.index else 350
            coke_ratio_kg = st.slider(
                "ç„¦æ¯”ï¼ˆkg/å¨é“æ°´ï¼‰",
                min_value=coke_ratio_min,
                max_value=coke_ratio_max,
                value=coke_ratio_current,
                step=1,
                help="è°ƒæ•´ç„¦ç‚­æ¶ˆè€—ä¸é“æ°´äº§é‡çš„æ¯”å€¼ï¼Œå•ä½ï¼škg/å¨é“æ°´"
            )
            coke_ratio = coke_ratio_kg / 1000
            # ç°åˆ†æ»‘å—ï¼ŒèŒƒå›´6-11
            luan_coal_ash_avg = st.slider(
                "æ½å®‰ç…¤ç°åˆ† (%)",
                min_value=6.0,
                max_value=11.0,
                value=float(X.loc[selected_date, 'luan_coal_ash_avg']) if selected_date in X.index else param_ranges['luan_coal_ash_avg']['current'],
                step=0.1,
                help="è°ƒæ•´æ½å®‰ç…¤çš„å¹³å‡ç°åˆ†å«é‡"
            )
            # é¼“é£æ¸©åº¦æ»‘å—ï¼ŒèŒƒå›´1150-1280
            blast_temp_avg = st.slider(
                "é¼“é£æ¸©åº¦ (Â°C)",
                min_value=1150.0,
                max_value=1280.0,
                value=float(X.loc[selected_date, 'blast_temp_avg']) if selected_date in X.index else param_ranges['blast_temp_avg']['current'],
                step=1.0,
                help="è°ƒæ•´å¹³å‡é¼“é£æ¸©åº¦"
            )
            # é¢„ä¼°æˆæœ¬å˜åŒ–ï¼ˆæ­£è´Ÿå¯¹ç§°ï¼‰
            # ç…¤æ¯”æ¯å‡å°‘1kg/å¨é“æ°´ï¼Œæˆæœ¬-20å…ƒï¼Œå¢åŠ +20å…ƒ
            # ç„¦æ¯”æ¯å‡å°‘1kg/å¨é“æ°´ï¼Œæˆæœ¬-30å…ƒï¼Œå¢åŠ +30å…ƒ
            # é£æ¸©æ¯å‡é«˜10åº¦+5å…ƒï¼Œé™ä½-5å…ƒ
            coal_cost = (int(X.loc[selected_date, 'coal_ratio'] * 1000) - coal_ratio_kg) * 20
            coke_cost = (coke_ratio_kg - int(X.loc[selected_date, 'coke_ratio'] * 1000) if 'coke_ratio' in X.columns else 350) * 30
            temp_cost = (blast_temp_avg - float(X.loc[selected_date, 'blast_temp_avg'])) / 10 * 5
            total_cost = coal_cost + coke_cost + temp_cost
            st.markdown(f"**é¢„ä¼°æˆæœ¬å˜åŒ–ï¼š** <span style='color:#2b7cff;font-size:1.2em;'>{total_cost:+.2f} å…ƒ</span> ", unsafe_allow_html=True)
        if st.button("ğŸ”„ é‡ç½®ä¸ºåŸå§‹å€¼"):
            st.rerun()
        
        with sim_col2:
            st.subheader("ğŸ“ˆ é¢„æµ‹å¯¹æ¯”")
            
            # åˆ›å»ºä»¿çœŸæ•°æ®
            if X is not None:
                simulation_data, original_data = create_simulation_data(
                    X, selected_date, coal_ratio, luan_coal_ash_avg, blast_temp_avg
                )
            else:
                simulation_data, original_data = None, None
            
            if simulation_data is not None and original_data is not None:
                # è·å–åŸå§‹é¢„æµ‹å€¼
                original_prediction = model.predict(original_data)[0]
                
                # è·å–ä»¿çœŸé¢„æµ‹å€¼
                simulation_prediction = model.predict(simulation_data)[0]
                
                # è®¡ç®—å˜åŒ–
                prediction_change = simulation_prediction - original_prediction
                change_percentage = (prediction_change / original_prediction) * 100
                
                # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                st.metric(
                    label="åŸå§‹é¢„æµ‹å€¼",
                    value=f"{original_prediction:.2f}",
                    delta=None
                )
                
                st.metric(
                    label="ä»¿çœŸé¢„æµ‹å€¼",
                    value=f"{simulation_prediction:.2f}",
                    delta=f"{prediction_change:.2f} ({change_percentage:+.2f}%)"
                )
                
                # æ˜¾ç¤ºå‚æ•°å˜åŒ–
                st.markdown("### å‚æ•°å˜åŒ–:")
                
                original_coal_ratio = float(original_data['coal_ratio'].iloc[0])
                original_ash = float(original_data['luan_coal_ash_avg'].iloc[0])
                original_temp = float(original_data['blast_temp_avg'].iloc[0])
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("ç…¤æ¯”ï¼ˆkg/å¨é“æ°´ï¼‰", f"{coal_ratio_kg}", f"{coal_ratio_kg - int(original_coal_ratio * 1000):+d}")
                    st.metric("ç°åˆ† (%)", f"{luan_coal_ash_avg:.2f}", f"{luan_coal_ash_avg - original_ash:+.2f}")
                with col2:
                    st.metric("æ¸©åº¦ (Â°C)", f"{blast_temp_avg:.1f}", f"{blast_temp_avg - original_temp:+.1f}")
        
        with sim_col3:
            st.subheader("ğŸ’¡ ä¼˜åŒ–å»ºè®®")
            
            if simulation_data is not None and original_data is not None:
                original_prediction = model.predict(original_data)[0]
                simulation_prediction = model.predict(simulation_data)[0]
                
                if simulation_prediction < original_prediction:
                    st.success("âœ… ä¼˜åŒ–æ•ˆæœ")
                    improvement = original_prediction - simulation_prediction
                    st.metric("ç¢³æ’æ”¾å‡å°‘", f"{improvement:.2f} å¨CO2")
                    
                    st.markdown("### ä¼˜åŒ–å»ºè®®:")
                    st.markdown("""
                    ğŸ¯ **å½“å‰å‚æ•°è°ƒæ•´æœ‰æ•ˆé™ä½äº†ç¢³æ’æ”¾**
                    
                    ğŸ“‹ **å»ºè®®æªæ–½:**
                    - ä¿æŒå½“å‰å‚æ•°è®¾ç½®
                    - ç›‘æ§ç”Ÿäº§ç¨³å®šæ€§
                    - è¯„ä¼°æˆæœ¬æ•ˆç›Š
                    """)
                else:
                    st.warning("âš ï¸ éœ€è¦è°ƒæ•´")
                    increase = simulation_prediction - original_prediction
                    st.metric("ç¢³æ’æ”¾å¢åŠ ", f"{increase:.2f} å¨CO2")
                    
                    st.markdown("### è°ƒæ•´å»ºè®®:")
                    st.markdown("""
                    ğŸ”§ **å½“å‰å‚æ•°è°ƒæ•´å¢åŠ äº†ç¢³æ’æ”¾**
                    
                    ğŸ“‹ **å»ºè®®æªæ–½:**
                    - é™ä½ç…¤æ¯”ç‡
                    - å‡å°‘ç°åˆ†å«é‡
                    - ä¼˜åŒ–é¼“é£æ¸©åº¦
                    - å¯»æ‰¾æœ€ä½³å¹³è¡¡ç‚¹
                    """)
            
            # æ˜¾ç¤ºå‚æ•°è¯´æ˜
            st.markdown("### å‚æ•°è¯´æ˜:")
            st.markdown("""
            **ç…¤æ¯”ç‡**: å½±å“ç‡ƒæ–™æ•ˆç‡å’Œç‡ƒçƒ§ç‰¹æ€§
            
            **ç°åˆ†å«é‡**: å½±å“ç‡ƒçƒ§æ•ˆç‡å’Œç‚‰æ¸£å½¢æˆ
            
            **é¼“é£æ¸©åº¦**: å½±å“ç‡ƒçƒ§ååº”å’Œçƒ­æ•ˆç‡
            """)
        
        # æ•æ„Ÿæ€§åˆ†æ
        st.markdown("---")
        st.subheader("ğŸ“Š å‚æ•°æ•æ„Ÿæ€§åˆ†æ")
        
        # æ•æ„Ÿæ€§åˆ†æå‚æ•°å»é™¤ç„¦ç‚­æ¶ˆè€—é‡
        st.markdown("---")
        sensitivity_param = st.selectbox(
            "é€‰æ‹©è¦åˆ†æçš„å‚æ•°",
            ["coal_ratio", "luan_coal_ash_avg", "blast_temp_avg"],
            format_func=lambda x: {
                    "coal_ratio": "ç…¤æ¯”ï¼ˆkg/å¨é“æ°´ï¼‰",
                "luan_coal_ash_avg": "æ½å®‰ç…¤ç°åˆ†",
                "blast_temp_avg": "é¼“é£æ¸©åº¦"
            }[x]
        )
        if st.button("ğŸ” å¼€å§‹æ•æ„Ÿæ€§åˆ†æ"):
            with st.spinner("æ­£åœ¨è¿›è¡Œæ•æ„Ÿæ€§åˆ†æ..."):
                param_range = param_ranges[sensitivity_param] if sensitivity_param in param_ranges else None
                if sensitivity_param == 'coal_ratio':
                    param_range = {'min': 110, 'max': 210, 'current': int(X.loc[selected_date, 'coal_ratio'] * 1000) if selected_date in X.index else int(param_ranges['coal_ratio']['current'] * 1000)}
                # å…¶ä½™å‚æ•°ä¸å˜
                param_values, predictions = create_sensitivity_analysis(
                    model, X, selected_date, sensitivity_param, param_range
                )
                if sensitivity_param == 'coal_ratio':
                    original_value = int(X.loc[selected_date, 'coal_ratio'] * 1000) if selected_date in X.index else param_range['current']
                else:
                    original_value = float(X.loc[selected_date, sensitivity_param]) if selected_date in X.index else param_range['current']
                # åç»­ç»˜å›¾ã€æŒ‡æ ‡ç­‰éƒ½ç”¨param_values
                if param_values is not None and predictions is not None:
                    # ç»˜åˆ¶æ•æ„Ÿæ€§åˆ†æå›¾
                    sensitivity_fig = plot_sensitivity_analysis(
                        param_values, predictions, sensitivity_param, original_value
                    )
                    if sensitivity_fig is not None:
                        st.pyplot(sensitivity_fig)
                        # åˆ†æç»“æœ
                        st.markdown("### ğŸ“ˆ æ•æ„Ÿæ€§åˆ†æç»“æœ:")
                        # æ‰¾åˆ°æœ€ä¼˜å€¼
                        min_prediction_idx = np.argmin(predictions)
                        optimal_value = param_values[min_prediction_idx]
                        min_prediction = predictions[min_prediction_idx]
                        # è®¡ç®—æ•æ„Ÿæ€§
                        sensitivity = (max(predictions) - min(predictions)) / (param_range['max'] - param_range['min'])
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æœ€ä¼˜å€¼", f"{optimal_value:.1f}")
                        with col2:
                            st.metric("æœ€ä½é¢„æµ‹", f"{min_prediction:.2f}")
                        with col3:
                            st.metric("æ•æ„Ÿæ€§", f"{sensitivity:.2f}")
                        # ä¼˜åŒ–å»ºè®®
                        st.markdown("### ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
                        import numpy as np
                        param_values_arr = np.array(param_values)
                        # å‚æ•°ä¸­æ–‡åå’Œå•ä½
                        param_zh = {
                            "coal_ratio": "ç…¤æ¯”",
                            "luan_coal_ash_avg": "æ½å®‰ç…¤ç°åˆ†",
                            "blast_temp_avg": "é¼“é£æ¸©åº¦"
                        }
                        param_unit = {
                            "coal_ratio": "kg/å¨é“æ°´",
                            "luan_coal_ash_avg": "%",
                            "blast_temp_avg": "Â°C"
                        }
                        # åˆç†èŒƒå›´
                        valid_range = {
                            "coal_ratio": (110, 210),
                            "luan_coal_ash_avg": (6.0, 11.0),
                            "blast_temp_avg": (1150.0, 1280.0)
                        }
                        if optimal_value != original_value and valid_range[sensitivity_param][0] <= optimal_value <= valid_range[sensitivity_param][1]:
                            improvement = predictions[np.argmin(np.abs(param_values_arr - original_value))] - min_prediction
                            st.success(f"ğŸ¯ å°†{param_zh[sensitivity_param]}è°ƒæ•´åˆ°{optimal_value:.1f}{param_unit[sensitivity_param]}å¯å‡å°‘ç¢³æ’æ”¾{improvement:.2f}å¨COâ‚‚")
                        else:
                            st.info("âœ… å½“å‰å‚æ•°è®¾ç½®å·²æ¥è¿‘æœ€ä¼˜ï¼Œæ— éœ€è°ƒæ•´")

    with tab4:
        # æ½å®‰ç…¤ç‰¹æ€§å½±å“æƒé‡åˆ†ææ¨¡å—
        st.markdown("---")
        st.header("æ½å®‰ç…¤ç‰¹æ€§å½±å“æƒé‡åˆ†æ")

        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
        weight_col1, weight_col2 = st.columns([2, 1])

        with weight_col1:
            st.subheader("ğŸ“Š ç‰¹å¾é‡è¦æ€§åˆ†æ")
            # è·å–ç‰¹å¾é‡è¦æ€§
            feature_importance = pd.DataFrame({
                'feature': X.columns,
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False)
            # ä¸­æ–‡åç´¢å¼•
            feature_importance['feature_zh'] = feature_importance['feature'].apply(lambda f: en2zh.get(f, f))
            # ç”¨plotlyç»˜åˆ¶æ¯ä¸ªæŸ±æ­£ä¸Šæ–¹æœ‰æ ‡ç­¾çš„æ¡å½¢å›¾
            import plotly.graph_objects as go
            fig = go.Figure(go.Bar(
                x=feature_importance['feature_zh'],
                y=feature_importance['importance'],
                marker_color='#2b7cff',
                text=[f"{v:.3f}" for v in feature_importance['importance']],
                textposition='outside'
            ))
            fig.update_layout(
                xaxis_title="ç‰¹å¾",
                yaxis_title="é‡è¦æ€§",
                margin=dict(l=10, r=10, t=60, b=30),
                height=350,
                yaxis_range=[0, max(feature_importance['importance']) * 1.15]
            )
            st.plotly_chart(fig, use_container_width=True)
            # æ˜¾ç¤ºè¯¦ç»†çš„ç‰¹å¾é‡è¦æ€§è¡¨æ ¼
            st.markdown("### ğŸ“‹ ç‰¹å¾é‡è¦æ€§æ’å")
            # ä¸ºç‰¹å¾æ·»åŠ åˆ†ç±»æ ‡ç­¾
            def categorize_feature(feature_name):
                if 'luan_coal' in feature_name:
                    return "æ½å®‰ç…¤ç‰¹æ€§"
                elif 'ratio' in feature_name:
                    return "æ¯”ç‡ç‰¹å¾"
                elif 'effect' in feature_name or 'input' in feature_name:
                    return "äº¤å‰ç‰¹å¾"
                elif 'blast' in feature_name:
                    return "é¼“é£å‚æ•°"
                elif 'coke' in feature_name:
                    return "ç„¦ç‚­å‚æ•°"
                elif 'iron' in feature_name:
                    return "äº§é‡å‚æ•°"
                else:
                    return "å…¶ä»–å‚æ•°"
            feature_importance['category'] = feature_importance['feature'].apply(categorize_feature)
            # æ˜¾ç¤ºå‰10ä¸ªé‡è¦ç‰¹å¾ï¼Œå…¨éƒ¨ç”¨ä¸­æ–‡å
            top_features = feature_importance.head(10)
            for idx, row in top_features.iterrows():
                category_color = {
                    "æ½å®‰ç…¤ç‰¹æ€§": "ğŸ”µ",
                    "æ¯”ç‡ç‰¹å¾": "ğŸŸ¢", 
                    "äº¤å‰ç‰¹å¾": "ğŸŸ¡",
                    "é¼“é£å‚æ•°": "ğŸŸ ",
                    "ç„¦ç‚­å‚æ•°": "ğŸ”´",
                    "äº§é‡å‚æ•°": "ğŸŸ£",
                    "å…¶ä»–å‚æ•°": "âšª"
                }
                category = str(row['category'])
                feature_zh = str(row['feature_zh'])
                st.markdown(f"{category_color.get(category, 'âšª')} **{feature_zh}** ({category}) - é‡è¦æ€§: {row['importance']:.4f}")

        with weight_col2:
            st.subheader("ğŸ¯ æ½å®‰ç…¤ç‰¹æ€§åˆ†æ")
            # è®¡ç®—æ½å®‰ç…¤ç›¸å…³ç‰¹å¾çš„é‡è¦æ€§
            luan_features = feature_importance[feature_importance['category'].isin(['æ½å®‰ç…¤ç‰¹æ€§', 'äº¤å‰ç‰¹å¾'])]
            luan_total_importance = luan_features['importance'].sum()
            total_importance = feature_importance['importance'].sum()
            luan_percentage = (luan_total_importance / total_importance) * 100
            # æƒé‡è¯´æ˜é—®å·
            st.markdown(
                f'<span style="font-size:1.1em;font-weight:bold;">æ½å®‰ç…¤ç‰¹æ€§æ€»æƒé‡</span>'
                f'<span title="æ­¤æƒé‡ä¸ºæ‰€æœ‰ä¸æ½å®‰ç…¤ç›¸å…³çš„ç‰¹å¾ï¼ˆåŒ…æ‹¬åŸå§‹ç‰¹å¾å’Œäº¤å‰ç‰¹å¾ï¼‰çš„é‡è¦æ€§å¾—åˆ†ä¹‹å’Œã€‚" style="cursor: pointer; color: #888;">â“</span>',
                unsafe_allow_html=True
            )
            st.metric(
                label="",
                value=f"{luan_percentage:.1f}%",
                delta=f"{luan_total_importance:.4f}"
            )
            # æ˜¾ç¤ºæ½å®‰ç…¤ç‰¹æ€§è¯¦æƒ…ï¼Œå…¨éƒ¨ç”¨ä¸­æ–‡å
            st.markdown("### ğŸ” æ½å®‰ç…¤ç‰¹æ€§è¯¦æƒ…:")
            for idx, row in luan_features.iterrows():
                importance_percent = (row['importance'] / total_importance) * 100
                st.markdown(f"**{row['feature_zh']}**: {importance_percent:.1f}%")
            # äº¤å‰ç‰¹å¾åˆ†æ
            cross_features = feature_importance[feature_importance['category'] == 'äº¤å‰ç‰¹å¾']
            if len(cross_features) > 0:
                st.markdown("### ğŸ§  äº¤å‰ç‰¹å¾åˆ†æ:")
                cross_total = cross_features['importance'].sum()
                cross_percentage = (cross_total / total_importance) * 100
                st.metric(
                    label="äº¤å‰ç‰¹å¾æƒé‡",
                    value=f"{cross_percentage:.1f}%",
                    delta=f"{cross_total:.4f}"
                )
                # åªå±•ç¤ºä¸€æ¡ä¸­æ–‡å…¬å¼åŠç‰©ç†å«ä¹‰
                st.markdown("**äº¤å‰ç‰¹å¾ç»¼åˆè®¡ç®—å…¬å¼ï¼š**")
                st.markdown("- äº¤å‰å½±å“ = ç…¤æ¯” Ã— (æŒ¥å‘åˆ† + å›ºå®šç¢³) - ç…¤æ¯” Ã— ç°åˆ†")
                st.markdown(
                    "> ç‰©ç†å«ä¹‰ï¼šç…¤æ¯”æå‡æ—¶ï¼Œç…¤ä¸­å¯ç‡ƒç»„åˆ†ï¼ˆæŒ¥å‘åˆ†ã€å›ºå®šç¢³ï¼‰æœ‰åŠ©äºé™ä½ç¢³æ’æ”¾ï¼Œç°åˆ†åˆ™èµ·ç¨€é‡Šå’Œè´Ÿé¢ä½œç”¨ã€‚è¯¥å…¬å¼ç»¼åˆåæ˜ ç…¤è´¨å¥½åå¯¹ç¢³æ’æ”¾çš„æ­£è´Ÿå½±å“ã€‚"
                )

    with tab5:
        # èƒ½åŠ›åˆ†æåŠæŠ€æœ¯æ€»ç»“
        st.markdown("---")
        st.subheader("æ ¸å¿ƒç®—æ³•è§£æï¼šä»ç‰¹å¾å·¥ç¨‹åˆ°æ™ºèƒ½å†³ç­–")
        # 1. åˆ›æ–°ç‰¹å¾å·¥ç¨‹ï¼šæ•æ‰æ½å®‰ç…¤çš„"æŒ‡çº¹"
        st.markdown("### 1. åˆ›æ–°ç‰¹å¾å·¥ç¨‹ï¼šæ•æ‰æ½å®‰ç…¤çš„'æŒ‡çº¹'")
        col_feat1, col_feat2 = st.columns(2)
        with col_feat1:
            st.markdown("#### åŸºç¡€ç‰¹å¾çš„å±€é™æ€§")
            st.markdown("""
            - ä»…ç”¨å•ä¸€ç‰¹å¾ï¼Œæ— æ³•æ•æ‰å®ƒä»¬ä¹‹é—´çš„å¤æ‚äº¤äº’ä½œç”¨ã€‚
            - æ˜“å¯¼è‡´æ¨¡å‹è¯¯åˆ¤ï¼Œé¢„æµ‹ç²¾åº¦å—é™ã€‚
            """)
            st.image("data/feature_limit_demo.png")
            st.markdown("<span style='font-size:0.95em;color:#888;'>å›¾ç‰‡æ¥æºï¼šscikit-learnå®˜æ–¹æ–‡æ¡£ï¼ŒPermutation Importance vs Random Forest Feature Importance (MDI)ï¼Œ<a href='https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html' target='_blank'>[åŸæ–‡é“¾æ¥]</a></span>", unsafe_allow_html=True)
        with col_feat2:
            st.markdown("#### å¼•å…¥å†¶é‡‘æœºç†çš„äº¤å‰ç‰¹å¾è®¾è®¡")
            st.markdown("ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬ç³»ç»Ÿç‹¬åˆ›æ€§åœ°æ„å»ºäº†ä»¥ä¸‹äº¤å‰ç‰¹å¾ï¼Œå°†ç…¤è´¨ç‰¹æ€§ä¸æ“ä½œå‚æ•°æ·±åº¦è€¦åˆï¼š")
            st.latex(r'æŒ¥å‘åˆ†å½±å“ = ç…¤æ¯” \times æ½å®‰ç…¤æŒ¥å‘åˆ†')
            st.caption("é‡åŒ–æŒ¥å‘åˆ†åœ¨é«˜å–·å¹ä¸‹çš„ç‡ƒçƒ§ä¿ƒè¿›æ•ˆåº”")
            st.latex(r'ç°åˆ†è´Ÿè· = ç…¤æ¯” \times æ½å®‰ç…¤ç°åˆ†')
            st.caption("é‡åŒ–ç°åˆ†åœ¨é«˜å–·å¹ä¸‹å¸¦æ¥çš„é¢å¤–çƒ­è€—å’Œæ¸£é‡è´Ÿè·")
            st.latex(r'æœ‰æ•ˆç¢³è¾“å…¥ = ç…¤æ¯” \times æ½å®‰ç…¤å›ºå®šç¢³')
            st.caption("é‡åŒ–å›ºå®šç¢³è¾“å…¥å¯¹ç¢³æ’æ”¾çš„ç›´æ¥è´¡çŒ®")
            st.markdown(
                "> ä¼ ç»Ÿæ¨¡å‹ä»…å°†ç…¤è´¨æŒ‡æ ‡ä½œä¸ºå­¤ç«‹è¾“å…¥ï¼Œå¿½ç•¥äº†å…¶åœ¨ä¸åŒå–·å¹æ°´å¹³ä¸‹çš„ååŒæ•ˆåº”ï¼Œå¯¼è‡´é¢„æµ‹ç²¾åº¦ç“¶é¢ˆã€‚"
            )
        # 2. æ™ºèƒ½æ¨¡å‹èƒ½åŠ›ï¼šä»æ•°æ®åˆ°æ´å¯Ÿ
        st.markdown("### 2. æ™ºèƒ½æ¨¡å‹èƒ½åŠ›ï¼šä»æ•°æ®åˆ°æ´å¯Ÿ")
        col_model1, col_model2 = st.columns(2)
        with col_model1:
            st.markdown("#### æ¨¡å‹é€‰æ‹©ä¸ä¼˜åŠ¿ï¼ˆXGBoostï¼‰")
            st.markdown("""
            æˆ‘ä»¬é€‰ç”¨ä¸šç•Œé¢†å…ˆçš„XGBoostæ¨¡å‹ï¼Œå…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºï¼š
            - é«˜æ•ˆæ‹Ÿåˆé«˜ç»´ã€éçº¿æ€§å·¥è‰ºå…³ç³»
            - å†…ç”Ÿæ€§å¤„ç†å¤šå˜é‡é—´çš„å¤æ‚äº¤äº’ä½œç”¨
            - è¾“å‡ºå¯è§£é‡Šçš„ç‰¹å¾è´¡çŒ®åº¦ï¼Œä¸ºå½’å› åˆ†ææä¾›ä¾æ®
            """)
            st.markdown("è¯æ®ï¼šå¦‚å³æ–¹ç‰¹å¾é‡è¦æ€§åˆ†ææ‰€ç¤ºï¼Œæœ¬ç³»ç»Ÿåˆ›å»ºçš„ç°åˆ†è´Ÿè·æ•ˆåº”ç­‰äº¤å‰ç‰¹å¾åœ¨æ¨¡å‹ä¸­å æ®ä¸»å¯¼åœ°ä½ï¼Œè¯æ˜æ¨¡å‹æˆåŠŸå­¦ä¹ å¹¶éªŒè¯äº†æˆ‘ä»¬ç‰¹å¾å·¥ç¨‹çš„æœ‰æ•ˆæ€§ã€‚")
        with col_model2:
            st.markdown("#### å­¦ä¹ æ•ˆæœéªŒè¯")
            st.image("data/cross_feature_importance.png", caption="äº¤å‰ç‰¹å¾åœ¨æ¨¡å‹é‡è¦æ€§æ’åºä¸­çš„ä¸»å¯¼åœ°ä½", use_container_width=True)

        # 3. è½¬åŒ–åº”ç”¨ä»·å€¼ï¼šèµ‹èƒ½ç”Ÿäº§å†³ç­–
        st.markdown("### 3. è½¬åŒ–åº”ç”¨ä»·å€¼ï¼šèµ‹èƒ½ç”Ÿäº§å†³ç­–")
        st.markdown("""
        åŸºäºä¸Šè¿°ç®—æ³•èƒ½åŠ›ï¼Œæœ¬ç³»ç»Ÿå°†å¤æ‚æ¨¡å‹è½¬åŒ–ä¸ºå¯¹ç”Ÿäº§æœ‰ç›´æ¥æŒ‡å¯¼æ„ä¹‰çš„æ´å¯Ÿï¼š
        - ä»æ•°æ®ä¸­æŒ–æ˜å¹¶é‡åŒ–å…³é”®å·¥è‰ºå½±å“å› ç´ 
        - ä¸ºæ“ä½œä¼˜åŒ–æä¾›é‡åŒ–ä¾æ®å’Œæ¨¡æ‹Ÿæ¨æ¼”
        - èµ‹èƒ½ä»ç»éªŒé©±åŠ¨åˆ°æ•°æ®é©±åŠ¨çš„å†³ç­–æ¨¡å¼è½¬å‹
        """)
        # æ ¸å¿ƒæŠ€æœ¯ä¼˜åŠ¿
        st.markdown("---")
        st.subheader("æ ¸å¿ƒæŠ€æœ¯ä¼˜åŠ¿")
        st.markdown("""
        1. ğŸ† **æ·±åº¦æœºç†ç†è§£ (Deep Mechanism Understanding)**  
        é€šè¿‡ç‹¬åˆ›çš„äº¤å‰ç‰¹å¾å·¥ç¨‹ï¼Œç³»ç»Ÿä¸å†æ˜¯"é»‘ç®±"ï¼Œè€Œæ˜¯èƒ½å¤Ÿæ·±å…¥ç†è§£å¹¶é‡åŒ–æ½å®‰ç…¤ç‰¹æ€§ï¼ˆæŒ¥å‘åˆ†ã€ç°åˆ†ç­‰ï¼‰ä¸ç”Ÿäº§å‚æ•°ï¼ˆç…¤æ¯”ï¼‰ä¹‹é—´çš„å¤æ‚äº¤äº’æœºç†ã€‚  
        â¡ï¸ è¯¦è§ä¸Šæ–¹"åˆ›æ–°ç‰¹å¾å·¥ç¨‹"è®¾è®¡åŸç†
        
        2. ğŸ“Š **æ™ºèƒ½å½’å› åˆ†æ (Intelligent Attribution Analysis)**  
        åŸºäºXGBoostæ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œç³»ç»Ÿèƒ½å¤Ÿå°†æŠ½è±¡çš„ç¢³æ’æ”¾æ³¢åŠ¨ï¼Œæ™ºèƒ½ã€å‡†ç¡®åœ°å½’å› åˆ°å…·ä½“çš„å·¥è‰ºå‚æ•°ä¸Šï¼Œå®ç°äº†ä»"çŸ¥å…¶ç„¶"åˆ°"çŸ¥å…¶æ‰€ä»¥ç„¶"çš„è·¨è¶Šã€‚  
        â¡ï¸ è¯¦è§"æ™ºèƒ½è¯Šæ–­åˆ†æ"ä¸­çš„SHAPç€‘å¸ƒå›¾
        
        3. ğŸ”® **ç²¾å‡†é¢„æµ‹ä¸ä¼˜åŒ– (Accurate Prediction & Optimization)**  
        å¾—ç›Šäºå¯¹æœºç†çš„æ·±åº¦ç†è§£å’Œå¼ºå¤§çš„æ¨¡å‹å­¦ä¹ èƒ½åŠ›ï¼Œç³»ç»Ÿä¸ä»…èƒ½å®ç°é«˜ç²¾åº¦çš„ç¢³æ’æ”¾é¢„æµ‹ï¼Œæ›´èƒ½æä¾›å‰ç»æ€§çš„ä»¿çœŸä¼˜åŒ–ï¼ŒæŒ‡å¯¼ç”Ÿäº§åœ¨æˆæœ¬å’Œç¯ä¿ä¹‹é—´æ‰¾åˆ°æœ€ä½³å¹³è¡¡ç‚¹ã€‚  
        â¡ï¸ è¯¦è§"ä»¿çœŸä¸ä¼˜åŒ–"æ¨¡å—çš„æ¨¡æ‹Ÿç»“æœ
        """)

if __name__ == "__main__":
    main()
